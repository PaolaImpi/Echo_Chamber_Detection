{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fc8465e8",
   "metadata": {},
   "source": [
    "# Dipole Moment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "106106ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import csv\n",
    "import datetime as dt\n",
    "import re\n",
    "import os\n",
    "import json\n",
    "import random\n",
    "import time,pickle\n",
    "import scipy.sparse as sp\n",
    "from operator import itemgetter\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b4441c7",
   "metadata": {},
   "source": [
    "###### Read Graph and communities file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "faf08d54",
   "metadata": {},
   "outputs": [],
   "source": [
    "path= \"C:/MyPath/Graphs/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "id": "4efcb5cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "G = nx.read_weighted_edgelist(path + \"retweet_graph_nationalkissingday_threshold_largest_CC.txt\",\n",
    "                              delimiter=\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "id": "3143937a",
   "metadata": {},
   "outputs": [],
   "source": [
    "f1 = open(\"C:/MyPath/community1_nationalkissingday.txt\" )\n",
    "f2 = open(\"C:/MyPath/community2_nationalkissingday.txt\" )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cb0172e",
   "metadata": {},
   "source": [
    "##### Compute DM metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "40597336",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convertIntoDirected(G):\n",
    "    for edge in G.edges():\n",
    "        node1 = edge[0];\n",
    "        node2 = edge[1];\n",
    "        G.add_edge(node2,node1);\n",
    "    return G;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "5c1263b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "G = convertIntoDirected(G)\n",
    "seed_nodes_num = int(len(G.nodes())*0.05); # seed nodes percenatage = 5 percent\n",
    "seed_nodes_num = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "a9c33e68",
   "metadata": {},
   "outputs": [],
   "source": [
    "lines1 = f1.readlines()\n",
    "lines1= list(filter(('\\n').__ne__, lines1 ))\n",
    "left = []\n",
    "dict_left = {}\n",
    "\n",
    "for line in lines1:\n",
    "    line = line.strip()\n",
    "    left.append(line)\n",
    "    dict_left[line] = 1\n",
    "    \n",
    "lines2 = f2.readlines()\n",
    "lines2= list(filter(('\\n').__ne__, lines2 ))\n",
    "right = []\n",
    "dict_right = {}\n",
    "\n",
    "for line in lines2:\n",
    "    line = line.strip()\n",
    "    right.append(line)\n",
    "    dict_right[line] = 1\n",
    "   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "db96e277",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getNodesFromLabelsWithHighestDegree(G,k,flag): # first take the nodes with the highest degree according to the \"flag\" and then take the top $k$\n",
    "    random_nodes = {}\n",
    "    dict_degrees = {}\n",
    "    for node in G.nodes():\n",
    "        dict_degrees[node] = G.degree(node)\n",
    "    sorted_dict = sorted(dict_degrees.items(), key=itemgetter(1), reverse=True) # sorts nodes by degrees\n",
    "#sorted_dict = sorted_dict[:k];\n",
    "    if(flag==\"left\"):\n",
    "        count = 0\n",
    "        for i in sorted_dict:\n",
    "            if(count>k):\n",
    "                break\n",
    "            if(not dict_left.__contains__(i[0])):\n",
    "                continue\n",
    "            random_nodes[i[0]] = i[1]\n",
    "            count += 1\n",
    "    elif(flag==\"right\"):\n",
    "        count = 0\n",
    "        for i in sorted_dict:\n",
    "            if(count>k):\n",
    "                break\n",
    "            if(not dict_right.__contains__(i[0])):\n",
    "                continue\n",
    "            random_nodes[i[0]] = i[1]\n",
    "            count += 1\n",
    "    else:\n",
    "        count = 0\n",
    "        for i in sorted_dict:\n",
    "            if(count>k/2):\n",
    "                break\n",
    "            if(not dict_left.__contains__(i[0])):\n",
    "                continue\n",
    "            random_nodes[i[0]] = i[1]\n",
    "            count += 1\n",
    "        count = 0\n",
    "        for i in sorted_dict:\n",
    "            if(count>k/2):\n",
    "                break\n",
    "            if(not dict_right.__contains__(i[0])):\n",
    "                continue\n",
    "            random_nodes[i[0]] = i[1]\n",
    "            count += 1\n",
    "\n",
    "    return random_nodes;\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "394afbda",
   "metadata": {},
   "outputs": [],
   "source": [
    "left_seed_nodes = getNodesFromLabelsWithHighestDegree(G,seed_nodes_num,'left')\n",
    "right_seed_nodes = getNodesFromLabelsWithHighestDegree(G,seed_nodes_num,'right')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "6417588a",
   "metadata": {},
   "outputs": [],
   "source": [
    "G1 = nx.DiGraph()\n",
    "\n",
    "dict_ids = {}\n",
    "dict_ideos = {}\n",
    "\n",
    "count = 0\n",
    "for node in G.nodes():\n",
    "    dict_ids[node] = count\n",
    "    count += 1\n",
    "    if(left_seed_nodes.__contains__(node)):\n",
    "        dict_ideos[node] = 1\n",
    "    elif(right_seed_nodes.__contains__(node)):\n",
    "        dict_ideos[node] = -1\n",
    "    else:\n",
    "        dict_ideos[node] = 0\n",
    "\n",
    "for node in G.nodes():\n",
    "    node_id = dict_ids[node]\n",
    "    node_ideo = dict_ideos[node]\n",
    "    G.add_node(node, ideo=node_ideo)\n",
    "    \n",
    "G1= nx.relabel_nodes(G, dict_ids, copy=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "a1b1655c",
   "metadata": {},
   "outputs": [],
   "source": [
    "savepath= \"C:/MyPath/MBLB_graphs/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "566e28cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "nx.write_gml(G1, savepath+ 'politics_reddit' + '_mblbgraph.gml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "4a00ec8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Model(G,corenode,tol=10**-5,save_xi=True):\n",
    "    #G: Graph to calculate opinions. The nodes have an attribute \"ideo\" with their ideology, set to 0 for all listeners, 1 and -1 for the elite.\n",
    "    #corenode: Nodes that belong to the seed (Identifiers from the Graph G)\n",
    "    #tol is the threshold for convergence. It will evaluate the difference between opinions at time t and t+1\n",
    "    #save_xi: boolean to save results\n",
    "    N=len(G.nodes())\n",
    "    #print N\n",
    "\n",
    "    #Get de adjacency matrix\n",
    "    Aij = nx.adjacency_matrix(G)\n",
    "    #Aij = sp.lil_matrix((N,N))\n",
    "   #print Aij.shape\n",
    "    #for o,d in G.edges():\n",
    "    #    Aij[o,d]=1\n",
    "\n",
    "    #Build the vectors with users opinions\n",
    "    macro_v_current=[]\n",
    "    v_current= []\n",
    "    v_new = []\n",
    "    dict_nodes = {}\n",
    "    \n",
    "    for nodo in G.nodes():\n",
    "        dict_nodes[G.nodes[nodo]['ideo']] = G.nodes[nodo]['ideo'] #first ideo was label\n",
    "        v_current.append(G.nodes[nodo]['ideo'])\n",
    "        v_new.append(0.0)\n",
    "\n",
    "    v_current = 1.*np.array(v_current)\n",
    "    #f2 = open(\"analyze_venezuela/results_iter_0\",\"wb\");\n",
    "    #pickle.dump(dict_nodes,f2);\n",
    "    #f2.close();\n",
    "    v_new = 1.*np.array(v_new)\n",
    "    \n",
    "    notconverged=len(v_current)\n",
    "    times = 0;\n",
    "    \n",
    "    #Do as many times as required for convergence\n",
    "    while notconverged > 0:\n",
    "        times=times+1\n",
    "        t=time.time()\n",
    "        \n",
    "        #for all nodes apart from corenode, calculate opinion as average of neighbors\n",
    "        for j in np.setdiff1d(range(len(v_current)),corenode):\n",
    "            nodosin=Aij.getrow(j).nonzero()[1]\n",
    "            if len(nodosin) > 0:\n",
    "                v_new[j]= np.mean(v_current[nodosin])\n",
    "            else:\n",
    "                v_new[j]=v_current[j]\n",
    "                #nodos_changed[j]=nodos_changed[j] or (v_new[j]!=v_current[j])\n",
    "       \n",
    "        #update opinion\n",
    "        for j in corenode:\n",
    "            v_new[j]=v_current[j]\n",
    "\n",
    "        diff=np.abs(v_current-v_new)\n",
    "        notconverged=len(diff[diff>tol])\n",
    "        v_current=v_new.copy()\n",
    "        zz = 0\n",
    "       #for nodo in G.nodes():\n",
    "            #dict_nodes[G.node[nodo]['label']] = v_current[zz];\n",
    "             #zz += 1;\n",
    "       #f1=open(\"analyze_venezuela/results_iter_\" + str(times),'wb')\n",
    "       #print v_current;\n",
    "       #pickle.dump(dict_nodes,f1)\n",
    "       #f1.close();\n",
    "\n",
    "    return v_current   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "91c7edf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def GetPolarizationIndex(ideos):\n",
    "    #Input: Vector with individuals Xi\n",
    "    #Output: Polarization index, Area Difference, Normalized Pole Distance\n",
    "    D=[]#POLE DISTANCE\n",
    "    AP=[]#POSSITIVE AREA\n",
    "    AN=[]#NEGATIVE AREA\n",
    "    cgp=[]#POSSITIVE GRAVITY CENTER\n",
    "    cgn=[]#NEGATIVE GRAVITY CENTER\n",
    "    \n",
    "    ideos.sort()\n",
    "    hist,edg=np.histogram(ideos,np.linspace(-1,1.1,50))\n",
    "    edg=edg[:len(edg)-1]\n",
    "    AP=sum(hist[edg>0])\n",
    "    AN=sum(hist[edg<0])\n",
    "    AP0=1.*AP/(AP+AN)\n",
    "    AN0=1.*AN/(AP+AN)\n",
    "    cgp=sum(hist[edg>0]*edg[edg>0])/sum(hist[edg>0])\n",
    "    cgn=sum(hist[edg<0]*edg[edg<0])/sum(hist[edg<0])\n",
    "    D=cgp-cgn\n",
    "    p1= 0.5*D*(1.-1.*abs(AP0-AN0))#polarization index\n",
    "    DA=1.*abs(AP0-AN0)/(AP0+AN0)#Areas Difference\n",
    "    D=0.5*D#Normalized Pole Distance\n",
    "    return p1,DA,D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "78d0986b",
   "metadata": {},
   "outputs": [],
   "source": [
    "G = nx.read_gml(savepath+ 'politics_reddit' + '_mblbgraph.gml');\n",
    "ideos = nx.get_node_attributes(G,'ideo');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "df307a53",
   "metadata": {},
   "outputs": [],
   "source": [
    "corenode = []\n",
    "\n",
    "for key in ideos.keys():\n",
    "    if(ideos[key]==1 or ideos[key]==-1):\n",
    "        corenode.append(key)\n",
    "corenode= list(map(int, corenode))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "a9b19a36",
   "metadata": {},
   "outputs": [],
   "source": [
    "v_current = Model(G,corenode)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "8d488f3f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.004862825825466136, 0.9941626470859319, 0.8330532515426113)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#polarization index, Areas Difference, Normalized Pole Distance\n",
    "GetPolarizationIndex(v_current)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
