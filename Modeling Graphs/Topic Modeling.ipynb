{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a53b7d25",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import os\n",
    "import json\n",
    "import csv\n",
    "from ast import literal_eval\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9eb1249b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['KMP_DUPLICATE_LIB_OK']='True'\n",
    "from octis.preprocessing.preprocessing import Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "d8e8bd4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "b7541aad",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\paola\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to\n",
      "[nltk_data]     C:\\Users\\paola\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('wordnet')\n",
    "nltk.download('omw-1.4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3c464f46",
   "metadata": {},
   "outputs": [],
   "source": [
    "path= \"C:MyPath/Topic/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "9e3eb3d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df= pd.read_csv(path+ \"vax_twitter.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "7e9d3fe0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df =df.groupby('username').agg({'text': ' '.join})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "1b465331",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(text):\n",
    "    tokens = re.split('\\W+',text)\n",
    "    return tokens\n",
    "\n",
    "df['token'] = df['text'].apply(tokenize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "e629e18d",
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = nltk.corpus.stopwords.words('english')\n",
    "stop_words.extend(['from', 'll', 'would', 'doesn', 're','aaaaaand','aaaaand','aaaand'])\n",
    "\n",
    "def remove_stopwords(text):\n",
    "    tokenized_text_without_stopwords = []\n",
    "    for token in text:\n",
    "        if token not in stop_words:\n",
    "            tokenized_text_without_stopwords.append(token)\n",
    "    return tokenized_text_without_stopwords\n",
    "\n",
    "df['token'] = df['token'].apply(remove_stopwords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "6389ba84",
   "metadata": {},
   "outputs": [],
   "source": [
    "#defining the object for lemmatization\n",
    "wn_lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "def lemmatizer(text):\n",
    "    lemm_text = [wn_lemmatizer.lemmatize(word) for word in text]\n",
    "    return lemm_text\n",
    "\n",
    "df['lemma'] = df['token'].apply(lemmatizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "de1d7188",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['lemmatized']= [' '.join(map(str, l)) for l in df['lemma']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "b5abba9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(path + \"vax_twitter_aggr.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "1e7478b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "txt_file = (path + \"vax_twitter_text.txt\")\n",
    "with open(txt_file, \"w\") as my_output_file:\n",
    "    for line in df['lemmatized'].tolist():\n",
    "        try:\n",
    "            my_output_file.write(\"\".join(line)+'\\n') \n",
    "        except:\n",
    "            pass\n",
    "    my_output_file.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "515caacd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "created vocab\n",
      "7500\n"
     ]
    }
   ],
   "source": [
    "#os.chdir(os.path.pardir)\n",
    "preprocessor = Preprocessing(vocabulary=None, max_features=None,remove_punctuation=True, min_df=5, lemmatize=False, \n",
    "                             stopword_list=None, min_chars=2, min_words_docs=3, split=True, save_original_indexes=True)\n",
    "dataset = preprocessor.preprocess_dataset(documents_path=path + \"vax_twitter_text.txt\" , labels_path=None)\n",
    "\n",
    "dataset.save(r\"C:\\MyPath\\Vax_twitter\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1ad9a7b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from octis.dataset.dataset import Dataset\n",
    "from octis.optimization.optimizer import Optimizer\n",
    "from skopt.space.space import Real, Categorical, Integer\n",
    "from octis.evaluation_metrics.coherence_metrics import Coherence\n",
    "from octis.evaluation_metrics.diversity_metrics import TopicDiversity\n",
    "from octis.models.ProdLDA import ProdLDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bb4b75a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = Dataset()\n",
    "dataset.load_custom_dataset_from_folder(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "758c0753",
   "metadata": {},
   "outputs": [],
   "source": [
    "epoch=50\n",
    "model= ProdLDA(solver='adam', num_epochs= epoch, num_topics=20)\n",
    "optimizer = Optimizer()\n",
    "npmi = Coherence(texts=dataset.get_corpus(), measure='c_npmi')\n",
    "topic_diversity = TopicDiversity()\n",
    "search_space = {\"num_layers\": Categorical({1, 2}), \n",
    "                \"num_neurons\": Categorical({50, 100, 150}),\n",
    "                \"num_topics\": Categorical({5, 8, 10, 15}),\n",
    "                \"activation\": Categorical({'sigmoid', 'relu', 'softplus'}), \n",
    "                \"dropout\": Real(0.2, 0.6)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a38cfb57",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current call:  0\n",
      "Epoch: [1/50]\tSamples: [16838/841900]\tTrain Loss: 1161.8715910498668\tTime: 0:00:06.626065\n",
      "Epoch: [1/50]\tSamples: [3609/180450]\tValidation Loss: 1105.152616505611\tTime: 0:00:00.706944\n",
      "Epoch: [2/50]\tSamples: [33676/841900]\tTrain Loss: 1116.8262325549213\tTime: 0:00:06.849839\n",
      "Epoch: [2/50]\tSamples: [3609/180450]\tValidation Loss: 1102.6820237816917\tTime: 0:00:00.744018\n",
      "Epoch: [3/50]\tSamples: [50514/841900]\tTrain Loss: 1114.011811488059\tTime: 0:00:06.647463\n",
      "Epoch: [3/50]\tSamples: [3609/180450]\tValidation Loss: 1103.4511799927266\tTime: 0:00:00.733302\n",
      "Epoch: [4/50]\tSamples: [67352/841900]\tTrain Loss: 1112.9609437057363\tTime: 0:00:06.665724\n",
      "Epoch: [4/50]\tSamples: [3609/180450]\tValidation Loss: 1101.994151989817\tTime: 0:00:00.741723\n",
      "Epoch: [5/50]\tSamples: [84190/841900]\tTrain Loss: 1110.856466517849\tTime: 0:00:06.616229\n",
      "Epoch: [5/50]\tSamples: [3609/180450]\tValidation Loss: 1098.539675658943\tTime: 0:00:00.731150\n",
      "Epoch: [6/50]\tSamples: [101028/841900]\tTrain Loss: 1108.1948035716275\tTime: 0:00:06.791854\n",
      "Epoch: [6/50]\tSamples: [3609/180450]\tValidation Loss: 1099.4328582839776\tTime: 0:00:00.729986\n",
      "Epoch: [7/50]\tSamples: [117866/841900]\tTrain Loss: 1110.3660824657095\tTime: 0:00:06.612034\n",
      "Epoch: [7/50]\tSamples: [3609/180450]\tValidation Loss: 1100.2691599993072\tTime: 0:00:00.736291\n",
      "Epoch: [8/50]\tSamples: [134704/841900]\tTrain Loss: 1108.147111748839\tTime: 0:00:06.667645\n",
      "Epoch: [8/50]\tSamples: [3609/180450]\tValidation Loss: 1101.6666769491203\tTime: 0:00:00.716853\n",
      "Epoch: [9/50]\tSamples: [151542/841900]\tTrain Loss: 1111.380875730305\tTime: 0:00:06.643539\n",
      "Epoch: [9/50]\tSamples: [3609/180450]\tValidation Loss: 1111.5598417151566\tTime: 0:00:00.720506\n",
      "Epoch: [10/50]\tSamples: [168380/841900]\tTrain Loss: 1109.660172837295\tTime: 0:00:06.691857\n",
      "Epoch: [10/50]\tSamples: [3609/180450]\tValidation Loss: 1107.223737531172\tTime: 0:00:00.740986\n",
      "Early stopping\n",
      "Current call:  1\n",
      "Epoch: [1/50]\tSamples: [16838/841900]\tTrain Loss: 1138.8082073704195\tTime: 0:00:10.485625\n",
      "Epoch: [1/50]\tSamples: [3609/180450]\tValidation Loss: 1127.7213227781242\tTime: 0:00:00.920180\n",
      "Epoch: [2/50]\tSamples: [33676/841900]\tTrain Loss: 1117.4825147870515\tTime: 0:00:10.575159\n",
      "Epoch: [2/50]\tSamples: [3609/180450]\tValidation Loss: 1160.9811289917568\tTime: 0:00:00.832455\n",
      "Epoch: [3/50]\tSamples: [50514/841900]\tTrain Loss: 1109.8338831982996\tTime: 0:00:10.322864\n",
      "Epoch: [3/50]\tSamples: [3609/180450]\tValidation Loss: 1119.694296701822\tTime: 0:00:00.813764\n",
      "Epoch: [4/50]\tSamples: [67352/841900]\tTrain Loss: 1108.3480776890906\tTime: 0:00:10.317466\n",
      "Epoch: [4/50]\tSamples: [3609/180450]\tValidation Loss: 1114.4406756546134\tTime: 0:00:00.805213\n",
      "Epoch: [5/50]\tSamples: [84190/841900]\tTrain Loss: 1103.4342697692719\tTime: 0:00:10.029388\n",
      "Epoch: [5/50]\tSamples: [3609/180450]\tValidation Loss: 1113.2576615102869\tTime: 0:00:00.785746\n",
      "Epoch: [6/50]\tSamples: [101028/841900]\tTrain Loss: 1098.4287603514001\tTime: 0:00:09.978818\n",
      "Epoch: [6/50]\tSamples: [3609/180450]\tValidation Loss: 1092.6358918242588\tTime: 0:00:00.805019\n",
      "Epoch: [7/50]\tSamples: [117866/841900]\tTrain Loss: 1095.5995027465312\tTime: 0:00:09.969296\n",
      "Epoch: [7/50]\tSamples: [3609/180450]\tValidation Loss: 1101.922436205493\tTime: 0:00:00.807244\n",
      "Epoch: [8/50]\tSamples: [134704/841900]\tTrain Loss: 1094.6396855124244\tTime: 0:00:09.977716\n",
      "Epoch: [8/50]\tSamples: [3609/180450]\tValidation Loss: 1095.515687777085\tTime: 0:00:00.808954\n",
      "Epoch: [9/50]\tSamples: [151542/841900]\tTrain Loss: 1096.0112468820525\tTime: 0:00:10.045888\n",
      "Epoch: [9/50]\tSamples: [3609/180450]\tValidation Loss: 1124.9251367025145\tTime: 0:00:00.789292\n",
      "Epoch: [10/50]\tSamples: [168380/841900]\tTrain Loss: 1095.3109347190182\tTime: 0:00:09.980465\n",
      "Epoch: [10/50]\tSamples: [3609/180450]\tValidation Loss: 1095.0955618765586\tTime: 0:00:00.798274\n",
      "Epoch: [11/50]\tSamples: [185218/841900]\tTrain Loss: 1093.4153502772747\tTime: 0:00:10.018830\n",
      "Epoch: [11/50]\tSamples: [3609/180450]\tValidation Loss: 1100.4787023327099\tTime: 0:00:00.790431\n",
      "Early stopping\n",
      "Current call:  2\n",
      "Epoch: [1/50]\tSamples: [16838/841900]\tTrain Loss: 1169.7024805313874\tTime: 0:00:08.356057\n",
      "Epoch: [1/50]\tSamples: [3609/180450]\tValidation Loss: 1117.103259104842\tTime: 0:00:00.798312\n",
      "Epoch: [2/50]\tSamples: [33676/841900]\tTrain Loss: 1127.9807365246206\tTime: 0:00:07.967070\n",
      "Epoch: [2/50]\tSamples: [3609/180450]\tValidation Loss: 1118.3487526842616\tTime: 0:00:00.772495\n",
      "Epoch: [3/50]\tSamples: [50514/841900]\tTrain Loss: 1120.5692781429561\tTime: 0:00:07.963973\n",
      "Epoch: [3/50]\tSamples: [3609/180450]\tValidation Loss: 1104.7423541839844\tTime: 0:00:00.761317\n",
      "Epoch: [4/50]\tSamples: [67352/841900]\tTrain Loss: 1118.2963751337422\tTime: 0:00:07.979162\n",
      "Epoch: [4/50]\tSamples: [3609/180450]\tValidation Loss: 1099.1514142703138\tTime: 0:00:00.759490\n",
      "Epoch: [5/50]\tSamples: [84190/841900]\tTrain Loss: 1119.1257897089406\tTime: 0:00:08.069545\n",
      "Epoch: [5/50]\tSamples: [3609/180450]\tValidation Loss: 1104.8175957675255\tTime: 0:00:00.760657\n",
      "Epoch: [6/50]\tSamples: [101028/841900]\tTrain Loss: 1120.2937932139637\tTime: 0:00:07.950339\n",
      "Epoch: [6/50]\tSamples: [3609/180450]\tValidation Loss: 1106.3770229374481\tTime: 0:00:00.778964\n",
      "Epoch: [7/50]\tSamples: [117866/841900]\tTrain Loss: 1120.0840196085028\tTime: 0:00:07.960830\n",
      "Epoch: [7/50]\tSamples: [3609/180450]\tValidation Loss: 1103.2123240076892\tTime: 0:00:00.761806\n",
      "Epoch: [8/50]\tSamples: [134704/841900]\tTrain Loss: 1118.8550411921694\tTime: 0:00:08.385589\n",
      "Epoch: [8/50]\tSamples: [3609/180450]\tValidation Loss: 1110.4504439855223\tTime: 0:00:00.808100\n",
      "Epoch: [9/50]\tSamples: [151542/841900]\tTrain Loss: 1119.4247716579036\tTime: 0:00:08.096368\n",
      "Epoch: [9/50]\tSamples: [3609/180450]\tValidation Loss: 1098.2438343161193\tTime: 0:00:00.762928\n",
      "Epoch: [10/50]\tSamples: [168380/841900]\tTrain Loss: 1119.1251424709455\tTime: 0:00:07.957011\n",
      "Epoch: [10/50]\tSamples: [3609/180450]\tValidation Loss: 1114.7830532176504\tTime: 0:00:00.784812\n",
      "Epoch: [11/50]\tSamples: [185218/841900]\tTrain Loss: 1118.4929248806643\tTime: 0:00:08.085383\n",
      "Epoch: [11/50]\tSamples: [3609/180450]\tValidation Loss: 1112.6752362799598\tTime: 0:00:00.782876\n",
      "Epoch: [12/50]\tSamples: [202056/841900]\tTrain Loss: 1117.5624683623444\tTime: 0:00:07.931535\n",
      "Epoch: [12/50]\tSamples: [3609/180450]\tValidation Loss: 1110.5135961095525\tTime: 0:00:00.773594\n",
      "Epoch: [13/50]\tSamples: [218894/841900]\tTrain Loss: 1118.4171743360093\tTime: 0:00:08.100467\n",
      "Epoch: [13/50]\tSamples: [3609/180450]\tValidation Loss: 1109.4582148145262\tTime: 0:00:00.760997\n",
      "Epoch: [14/50]\tSamples: [235732/841900]\tTrain Loss: 1117.4955674296166\tTime: 0:00:07.918767\n",
      "Epoch: [14/50]\tSamples: [3609/180450]\tValidation Loss: 1112.530534557703\tTime: 0:00:00.784732\n",
      "Early stopping\n",
      "Current call:  3\n",
      "Epoch: [1/50]\tSamples: [16838/841900]\tTrain Loss: 1126.8084590942224\tTime: 0:00:09.743034\n",
      "Epoch: [1/50]\tSamples: [3609/180450]\tValidation Loss: 1107.9241866579212\tTime: 0:00:00.835907\n",
      "Epoch: [2/50]\tSamples: [33676/841900]\tTrain Loss: 1102.4763307708477\tTime: 0:00:09.465838\n",
      "Epoch: [2/50]\tSamples: [3609/180450]\tValidation Loss: 1110.0718397149487\tTime: 0:00:00.853226\n",
      "Epoch: [3/50]\tSamples: [50514/841900]\tTrain Loss: 1100.4532199564646\tTime: 0:00:09.472932\n",
      "Epoch: [3/50]\tSamples: [3609/180450]\tValidation Loss: 1112.2521041147131\tTime: 0:00:00.875016\n",
      "Epoch: [4/50]\tSamples: [67352/841900]\tTrain Loss: 1098.1182825369654\tTime: 0:00:09.909330\n",
      "Epoch: [4/50]\tSamples: [3609/180450]\tValidation Loss: 1085.9989436131893\tTime: 0:00:00.793458\n",
      "Epoch: [5/50]\tSamples: [84190/841900]\tTrain Loss: 1099.2104645880968\tTime: 0:00:09.375035\n",
      "Epoch: [5/50]\tSamples: [3609/180450]\tValidation Loss: 1102.6934435287649\tTime: 0:00:00.819904\n",
      "Epoch: [6/50]\tSamples: [101028/841900]\tTrain Loss: 1096.3667254263862\tTime: 0:00:09.354334\n",
      "Epoch: [6/50]\tSamples: [3609/180450]\tValidation Loss: 1087.4746634931769\tTime: 0:00:00.799066\n",
      "Epoch: [7/50]\tSamples: [117866/841900]\tTrain Loss: 1097.7148202319995\tTime: 0:00:09.391516\n",
      "Epoch: [7/50]\tSamples: [3609/180450]\tValidation Loss: 1096.0363977209754\tTime: 0:00:00.805431\n",
      "Epoch: [8/50]\tSamples: [134704/841900]\tTrain Loss: 1097.6142619883226\tTime: 0:00:09.390250\n",
      "Epoch: [8/50]\tSamples: [3609/180450]\tValidation Loss: 1097.2228526989818\tTime: 0:00:00.803873\n",
      "Epoch: [9/50]\tSamples: [151542/841900]\tTrain Loss: 1096.7822229521535\tTime: 0:00:09.395722\n",
      "Epoch: [9/50]\tSamples: [3609/180450]\tValidation Loss: 1093.355482820726\tTime: 0:00:00.808665\n",
      "Early stopping\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current call:  4\n",
      "Epoch: [1/50]\tSamples: [16838/841900]\tTrain Loss: 1172.5458333642653\tTime: 0:00:09.800034\n",
      "Epoch: [1/50]\tSamples: [3609/180450]\tValidation Loss: 1.2463222425346956e+20\tTime: 0:00:00.827126\n",
      "Epoch: [2/50]\tSamples: [33676/841900]\tTrain Loss: 1120.5585993757609\tTime: 0:00:09.474563\n",
      "Epoch: [2/50]\tSamples: [3609/180450]\tValidation Loss: 6.324651085486597e+17\tTime: 0:00:00.801619\n",
      "Epoch: [3/50]\tSamples: [50514/841900]\tTrain Loss: 1109.6496427467819\tTime: 0:00:09.619173\n",
      "Epoch: [3/50]\tSamples: [3609/180450]\tValidation Loss: 1113.3254131381616\tTime: 0:00:00.812191\n",
      "Epoch: [4/50]\tSamples: [67352/841900]\tTrain Loss: 1103.818175870798\tTime: 0:00:09.478268\n",
      "Epoch: [4/50]\tSamples: [3609/180450]\tValidation Loss: 1093.0357667030341\tTime: 0:00:00.807607\n",
      "Epoch: [5/50]\tSamples: [84190/841900]\tTrain Loss: 1097.1533414236028\tTime: 0:00:09.385010\n",
      "Epoch: [5/50]\tSamples: [3609/180450]\tValidation Loss: 1101.3554925619978\tTime: 0:00:00.807960\n",
      "Epoch: [6/50]\tSamples: [101028/841900]\tTrain Loss: 1094.5550212178184\tTime: 0:00:09.421350\n",
      "Epoch: [6/50]\tSamples: [3609/180450]\tValidation Loss: 1098.6183093698046\tTime: 0:00:00.818067\n",
      "Epoch: [7/50]\tSamples: [117866/841900]\tTrain Loss: 1092.8502463474313\tTime: 0:00:09.420169\n",
      "Epoch: [7/50]\tSamples: [3609/180450]\tValidation Loss: 1110.1694239877736\tTime: 0:00:00.796029\n",
      "Epoch: [8/50]\tSamples: [134704/841900]\tTrain Loss: 1097.0682915033842\tTime: 0:00:09.435693\n",
      "Epoch: [8/50]\tSamples: [3609/180450]\tValidation Loss: 1096.8041917775006\tTime: 0:00:00.809853\n",
      "Epoch: [9/50]\tSamples: [151542/841900]\tTrain Loss: 1093.618434939989\tTime: 0:00:09.628595\n",
      "Epoch: [9/50]\tSamples: [3609/180450]\tValidation Loss: 1092.5354723001524\tTime: 0:00:00.789268\n",
      "Epoch: [10/50]\tSamples: [168380/841900]\tTrain Loss: 1092.188359494475\tTime: 0:00:09.448812\n",
      "Epoch: [10/50]\tSamples: [3609/180450]\tValidation Loss: 1091.9936876558604\tTime: 0:00:00.802818\n",
      "Epoch: [11/50]\tSamples: [185218/841900]\tTrain Loss: 1092.173673547069\tTime: 0:00:09.478703\n",
      "Epoch: [11/50]\tSamples: [3609/180450]\tValidation Loss: 1082.1458414510598\tTime: 0:00:00.821921\n",
      "Epoch: [12/50]\tSamples: [202056/841900]\tTrain Loss: 1090.7066825688175\tTime: 0:00:09.449395\n",
      "Epoch: [12/50]\tSamples: [3609/180450]\tValidation Loss: 1080.436344035744\tTime: 0:00:00.803888\n",
      "Epoch: [13/50]\tSamples: [218894/841900]\tTrain Loss: 1091.3209378004271\tTime: 0:00:09.495806\n",
      "Epoch: [13/50]\tSamples: [3609/180450]\tValidation Loss: 1098.0888966819064\tTime: 0:00:00.801380\n",
      "Epoch: [14/50]\tSamples: [235732/841900]\tTrain Loss: 1089.8102616141225\tTime: 0:00:09.641734\n",
      "Epoch: [14/50]\tSamples: [3609/180450]\tValidation Loss: 1124.9524755818786\tTime: 0:00:00.832516\n",
      "Epoch: [15/50]\tSamples: [252570/841900]\tTrain Loss: 1092.6302497339072\tTime: 0:00:09.451848\n",
      "Epoch: [15/50]\tSamples: [3609/180450]\tValidation Loss: 1094.375563911402\tTime: 0:00:00.809393\n",
      "Epoch: [16/50]\tSamples: [269408/841900]\tTrain Loss: 1089.1499049536392\tTime: 0:00:09.477405\n",
      "Epoch: [16/50]\tSamples: [3609/180450]\tValidation Loss: 1097.2425333151496\tTime: 0:00:00.807827\n",
      "Epoch: [17/50]\tSamples: [286246/841900]\tTrain Loss: 1090.0688902844386\tTime: 0:00:09.463583\n",
      "Epoch: [17/50]\tSamples: [3609/180450]\tValidation Loss: 1094.7512246943406\tTime: 0:00:00.800739\n",
      "Early stopping\n",
      "Current call:  5\n",
      "Epoch: [1/50]\tSamples: [16838/841900]\tTrain Loss: 1163.5289348833833\tTime: 0:00:06.925323\n",
      "Epoch: [1/50]\tSamples: [3609/180450]\tValidation Loss: 1137.222814816258\tTime: 0:00:00.774387\n",
      "Epoch: [2/50]\tSamples: [33676/841900]\tTrain Loss: 1126.8836829995073\tTime: 0:00:06.651901\n",
      "Epoch: [2/50]\tSamples: [3609/180450]\tValidation Loss: 1124.1273584701441\tTime: 0:00:00.733527\n",
      "Epoch: [3/50]\tSamples: [50514/841900]\tTrain Loss: 1118.8712485454218\tTime: 0:00:06.629047\n",
      "Epoch: [3/50]\tSamples: [3609/180450]\tValidation Loss: 1127.2420695223745\tTime: 0:00:00.730804\n",
      "Epoch: [4/50]\tSamples: [67352/841900]\tTrain Loss: 1109.9403863488417\tTime: 0:00:06.719978\n",
      "Epoch: [4/50]\tSamples: [3609/180450]\tValidation Loss: 1116.7641351265931\tTime: 0:00:00.750284\n",
      "Epoch: [5/50]\tSamples: [84190/841900]\tTrain Loss: 1112.5330960615497\tTime: 0:00:06.662236\n",
      "Epoch: [5/50]\tSamples: [3609/180450]\tValidation Loss: 1114.9555256823219\tTime: 0:00:00.740432\n",
      "Epoch: [6/50]\tSamples: [101028/841900]\tTrain Loss: 1106.3543257345736\tTime: 0:00:06.620017\n",
      "Epoch: [6/50]\tSamples: [3609/180450]\tValidation Loss: 1103.131201943059\tTime: 0:00:00.757579\n",
      "Epoch: [7/50]\tSamples: [117866/841900]\tTrain Loss: 1104.4066124845958\tTime: 0:00:06.651042\n",
      "Epoch: [7/50]\tSamples: [3609/180450]\tValidation Loss: 1086.3066368367276\tTime: 0:00:00.761214\n",
      "Epoch: [8/50]\tSamples: [134704/841900]\tTrain Loss: 1100.4459533437666\tTime: 0:00:06.626987\n",
      "Epoch: [8/50]\tSamples: [3609/180450]\tValidation Loss: 1089.8813247913204\tTime: 0:00:00.760929\n",
      "Epoch: [9/50]\tSamples: [151542/841900]\tTrain Loss: 1100.9950014099202\tTime: 0:00:06.614734\n",
      "Epoch: [9/50]\tSamples: [3609/180450]\tValidation Loss: 1109.1417836701648\tTime: 0:00:00.759125\n",
      "Epoch: [10/50]\tSamples: [168380/841900]\tTrain Loss: 1103.0284045249214\tTime: 0:00:06.787598\n",
      "Epoch: [10/50]\tSamples: [3609/180450]\tValidation Loss: 1098.8573087680106\tTime: 0:00:00.740384\n",
      "Epoch: [11/50]\tSamples: [185218/841900]\tTrain Loss: 1101.3571684910178\tTime: 0:00:06.621704\n",
      "Epoch: [11/50]\tSamples: [3609/180450]\tValidation Loss: 1094.0758720603005\tTime: 0:00:00.768749\n",
      "Epoch: [12/50]\tSamples: [202056/841900]\tTrain Loss: 1102.1015137820702\tTime: 0:00:06.621984\n",
      "Epoch: [12/50]\tSamples: [3609/180450]\tValidation Loss: 1101.5540364583333\tTime: 0:00:00.747725\n",
      "Early stopping\n",
      "Current call:  6\n",
      "Epoch: [1/50]\tSamples: [16838/841900]\tTrain Loss: 1164.1883320906395\tTime: 0:00:09.874785\n",
      "Epoch: [1/50]\tSamples: [3609/180450]\tValidation Loss: 728063148439521.1\tTime: 0:00:00.831764\n",
      "Epoch: [2/50]\tSamples: [33676/841900]\tTrain Loss: 1141.3426928789233\tTime: 0:00:09.605980\n",
      "Epoch: [2/50]\tSamples: [3609/180450]\tValidation Loss: 1229.400614674252\tTime: 0:00:00.788371\n",
      "Epoch: [3/50]\tSamples: [50514/841900]\tTrain Loss: 1126.9741851375284\tTime: 0:00:09.644595\n",
      "Epoch: [3/50]\tSamples: [3609/180450]\tValidation Loss: 1133.0987851551677\tTime: 0:00:00.795811\n",
      "Epoch: [4/50]\tSamples: [67352/841900]\tTrain Loss: 1114.0461604703646\tTime: 0:00:09.527994\n",
      "Epoch: [4/50]\tSamples: [3609/180450]\tValidation Loss: 1127.7476767066707\tTime: 0:00:00.788332\n",
      "Epoch: [5/50]\tSamples: [84190/841900]\tTrain Loss: 1107.8786417957383\tTime: 0:00:09.677326\n",
      "Epoch: [5/50]\tSamples: [3609/180450]\tValidation Loss: 1110.9119567617415\tTime: 0:00:00.792762\n",
      "Epoch: [6/50]\tSamples: [101028/841900]\tTrain Loss: 1104.1980329323926\tTime: 0:00:09.554479\n",
      "Epoch: [6/50]\tSamples: [3609/180450]\tValidation Loss: 1102.178130520054\tTime: 0:00:00.802187\n",
      "Epoch: [7/50]\tSamples: [117866/841900]\tTrain Loss: 1102.2135800707013\tTime: 0:00:09.564084\n",
      "Epoch: [7/50]\tSamples: [3609/180450]\tValidation Loss: 1100.247832025838\tTime: 0:00:00.779661\n",
      "Epoch: [8/50]\tSamples: [134704/841900]\tTrain Loss: 1099.308018588442\tTime: 0:00:09.514412\n",
      "Epoch: [8/50]\tSamples: [3609/180450]\tValidation Loss: 1106.3817626073705\tTime: 0:00:00.804125\n",
      "Epoch: [9/50]\tSamples: [151542/841900]\tTrain Loss: 1097.3962159624064\tTime: 0:00:09.507286\n",
      "Epoch: [9/50]\tSamples: [3609/180450]\tValidation Loss: 1110.1077839256027\tTime: 0:00:00.803665\n",
      "Epoch: [10/50]\tSamples: [168380/841900]\tTrain Loss: 1096.5721267789004\tTime: 0:00:09.532537\n",
      "Epoch: [10/50]\tSamples: [3609/180450]\tValidation Loss: 1118.5488708783596\tTime: 0:00:00.805918\n",
      "Epoch: [11/50]\tSamples: [185218/841900]\tTrain Loss: 1096.5611651867243\tTime: 0:00:09.626317\n",
      "Epoch: [11/50]\tSamples: [3609/180450]\tValidation Loss: 1105.3177337688765\tTime: 0:00:00.793698\n",
      "Epoch: [12/50]\tSamples: [202056/841900]\tTrain Loss: 1096.0149622621636\tTime: 0:00:09.554132\n",
      "Epoch: [12/50]\tSamples: [3609/180450]\tValidation Loss: 1099.6640105465503\tTime: 0:00:00.791223\n",
      "Epoch: [13/50]\tSamples: [218894/841900]\tTrain Loss: 1095.6171865792892\tTime: 0:00:09.497217\n",
      "Epoch: [13/50]\tSamples: [3609/180450]\tValidation Loss: 1094.939907176503\tTime: 0:00:00.781819\n",
      "Epoch: [14/50]\tSamples: [235732/841900]\tTrain Loss: 1097.1889700635281\tTime: 0:00:09.505143\n",
      "Epoch: [14/50]\tSamples: [3609/180450]\tValidation Loss: 1094.7832458783596\tTime: 0:00:00.793203\n",
      "Epoch: [15/50]\tSamples: [252570/841900]\tTrain Loss: 1095.627598101091\tTime: 0:00:09.521339\n",
      "Epoch: [15/50]\tSamples: [3609/180450]\tValidation Loss: 1102.8924325471044\tTime: 0:00:00.795205\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [16/50]\tSamples: [269408/841900]\tTrain Loss: 1095.401665990802\tTime: 0:00:09.503535\n",
      "Epoch: [16/50]\tSamples: [3609/180450]\tValidation Loss: 1100.2279614548697\tTime: 0:00:00.778240\n",
      "Epoch: [17/50]\tSamples: [286246/841900]\tTrain Loss: 1093.8362599082989\tTime: 0:00:09.571467\n",
      "Epoch: [17/50]\tSamples: [3609/180450]\tValidation Loss: 1099.321759620047\tTime: 0:00:00.794347\n",
      "Epoch: [18/50]\tSamples: [303084/841900]\tTrain Loss: 1094.2966260745784\tTime: 0:00:09.459016\n",
      "Epoch: [18/50]\tSamples: [3609/180450]\tValidation Loss: 1103.7960085679897\tTime: 0:00:00.793583\n",
      "Epoch: [19/50]\tSamples: [319922/841900]\tTrain Loss: 1094.2210122663628\tTime: 0:00:09.460917\n",
      "Epoch: [19/50]\tSamples: [3609/180450]\tValidation Loss: 1102.0726309226932\tTime: 0:00:00.789517\n",
      "Early stopping\n",
      "Current call:  7\n",
      "Epoch: [1/50]\tSamples: [16838/841900]\tTrain Loss: 1185.284194723361\tTime: 0:00:10.048525\n",
      "Epoch: [1/50]\tSamples: [3609/180450]\tValidation Loss: 8.311749132532169e+19\tTime: 0:00:00.851981\n",
      "Epoch: [2/50]\tSamples: [33676/841900]\tTrain Loss: 1156.1550964580208\tTime: 0:00:09.754600\n",
      "Epoch: [2/50]\tSamples: [3609/180450]\tValidation Loss: 1.529870420448777e+24\tTime: 0:00:00.818818\n",
      "Epoch: [3/50]\tSamples: [50514/841900]\tTrain Loss: 1145.665308620545\tTime: 0:00:09.764794\n",
      "Epoch: [3/50]\tSamples: [3609/180450]\tValidation Loss: 1564.0867633433777\tTime: 0:00:00.791878\n",
      "Epoch: [4/50]\tSamples: [67352/841900]\tTrain Loss: 1133.238452233984\tTime: 0:00:09.781011\n",
      "Epoch: [4/50]\tSamples: [3609/180450]\tValidation Loss: 1117.231275110834\tTime: 0:00:00.795343\n",
      "Epoch: [5/50]\tSamples: [84190/841900]\tTrain Loss: 1121.5777853374343\tTime: 0:00:09.750431\n",
      "Epoch: [5/50]\tSamples: [3609/180450]\tValidation Loss: 1127.7954939041285\tTime: 0:00:00.811508\n",
      "Epoch: [6/50]\tSamples: [101028/841900]\tTrain Loss: 1119.6858406325164\tTime: 0:00:09.695410\n",
      "Epoch: [6/50]\tSamples: [3609/180450]\tValidation Loss: 1111.745287389166\tTime: 0:00:00.798133\n",
      "Epoch: [7/50]\tSamples: [117866/841900]\tTrain Loss: 1116.216333423945\tTime: 0:00:09.646842\n",
      "Epoch: [7/50]\tSamples: [3609/180450]\tValidation Loss: 1115.7941977737946\tTime: 0:00:00.786548\n",
      "Epoch: [8/50]\tSamples: [134704/841900]\tTrain Loss: 1116.012981008359\tTime: 0:00:09.658111\n",
      "Epoch: [8/50]\tSamples: [3609/180450]\tValidation Loss: 1123.718976213979\tTime: 0:00:00.794621\n",
      "Epoch: [9/50]\tSamples: [151542/841900]\tTrain Loss: 1114.7911598213723\tTime: 0:00:10.028161\n",
      "Epoch: [9/50]\tSamples: [3609/180450]\tValidation Loss: 1122.2261328016764\tTime: 0:00:00.826318\n",
      "Epoch: [10/50]\tSamples: [168380/841900]\tTrain Loss: 1113.961044171967\tTime: 0:00:09.840313\n",
      "Epoch: [10/50]\tSamples: [3609/180450]\tValidation Loss: 1109.3367714611043\tTime: 0:00:00.794393\n",
      "Epoch: [11/50]\tSamples: [185218/841900]\tTrain Loss: 1112.0845644373496\tTime: 0:00:09.729469\n",
      "Epoch: [11/50]\tSamples: [3609/180450]\tValidation Loss: 1114.8173040705528\tTime: 0:00:00.780140\n",
      "Epoch: [12/50]\tSamples: [202056/841900]\tTrain Loss: 1114.7697518726245\tTime: 0:00:09.624561\n",
      "Epoch: [12/50]\tSamples: [3609/180450]\tValidation Loss: 1112.5484000502217\tTime: 0:00:00.807614\n",
      "Epoch: [13/50]\tSamples: [218894/841900]\tTrain Loss: 1112.5891369920344\tTime: 0:00:09.688579\n",
      "Epoch: [13/50]\tSamples: [3609/180450]\tValidation Loss: 1117.9620020045372\tTime: 0:00:00.778559\n",
      "Epoch: [14/50]\tSamples: [235732/841900]\tTrain Loss: 1112.9148275164898\tTime: 0:00:09.647616\n",
      "Epoch: [14/50]\tSamples: [3609/180450]\tValidation Loss: 1112.3881436815946\tTime: 0:00:00.814826\n",
      "Epoch: [15/50]\tSamples: [252570/841900]\tTrain Loss: 1110.7597286225725\tTime: 0:00:09.673762\n",
      "Epoch: [15/50]\tSamples: [3609/180450]\tValidation Loss: 1115.9561772651705\tTime: 0:00:00.789694\n",
      "Early stopping\n",
      "Current call:  8\n",
      "Epoch: [1/50]\tSamples: [16838/841900]\tTrain Loss: 1173.1184494103738\tTime: 0:00:09.989218\n",
      "Epoch: [1/50]\tSamples: [3609/180450]\tValidation Loss: 1158.241443916251\tTime: 0:00:00.831636\n",
      "Epoch: [2/50]\tSamples: [33676/841900]\tTrain Loss: 1136.5053722537007\tTime: 0:00:09.711130\n",
      "Epoch: [2/50]\tSamples: [3609/180450]\tValidation Loss: 1135.572636334511\tTime: 0:00:00.805538\n",
      "Epoch: [3/50]\tSamples: [50514/841900]\tTrain Loss: 1125.7063487350042\tTime: 0:00:09.863767\n",
      "Epoch: [3/50]\tSamples: [3609/180450]\tValidation Loss: 1134.4640942132517\tTime: 0:00:00.799154\n",
      "Epoch: [4/50]\tSamples: [67352/841900]\tTrain Loss: 1120.0220688161635\tTime: 0:00:09.659937\n",
      "Epoch: [4/50]\tSamples: [3609/180450]\tValidation Loss: 1123.6012902855707\tTime: 0:00:00.788188\n",
      "Epoch: [5/50]\tSamples: [84190/841900]\tTrain Loss: 1119.5981027730245\tTime: 0:00:09.692005\n",
      "Epoch: [5/50]\tSamples: [3609/180450]\tValidation Loss: 1112.9472125891868\tTime: 0:00:00.804467\n",
      "Epoch: [6/50]\tSamples: [101028/841900]\tTrain Loss: 1118.3978212181896\tTime: 0:00:09.679114\n",
      "Epoch: [6/50]\tSamples: [3609/180450]\tValidation Loss: 1113.523742726517\tTime: 0:00:00.785501\n",
      "Epoch: [7/50]\tSamples: [117866/841900]\tTrain Loss: 1113.0867968784798\tTime: 0:00:09.703246\n",
      "Epoch: [7/50]\tSamples: [3609/180450]\tValidation Loss: 1108.976294615025\tTime: 0:00:00.791126\n",
      "Epoch: [8/50]\tSamples: [134704/841900]\tTrain Loss: 1115.7518797001203\tTime: 0:00:09.671356\n",
      "Epoch: [8/50]\tSamples: [3609/180450]\tValidation Loss: 1141.4305485201926\tTime: 0:00:00.792081\n",
      "Epoch: [9/50]\tSamples: [151542/841900]\tTrain Loss: 1110.391228232365\tTime: 0:00:09.715101\n",
      "Epoch: [9/50]\tSamples: [3609/180450]\tValidation Loss: 1109.0377046749445\tTime: 0:00:00.791923\n",
      "Epoch: [10/50]\tSamples: [168380/841900]\tTrain Loss: 1110.3743014776844\tTime: 0:00:09.688365\n",
      "Epoch: [10/50]\tSamples: [3609/180450]\tValidation Loss: 1107.941240377788\tTime: 0:00:00.801437\n",
      "Epoch: [11/50]\tSamples: [185218/841900]\tTrain Loss: 1112.6138456820138\tTime: 0:00:09.668670\n",
      "Epoch: [11/50]\tSamples: [3609/180450]\tValidation Loss: 1109.4304162012504\tTime: 0:00:00.784183\n",
      "Epoch: [12/50]\tSamples: [202056/841900]\tTrain Loss: 1113.4572958202568\tTime: 0:00:09.649597\n",
      "Epoch: [12/50]\tSamples: [3609/180450]\tValidation Loss: 1113.5212154076614\tTime: 0:00:00.792836\n",
      "Epoch: [13/50]\tSamples: [218894/841900]\tTrain Loss: 1111.1943968059134\tTime: 0:00:09.671946\n",
      "Epoch: [13/50]\tSamples: [3609/180450]\tValidation Loss: 1109.2673253931143\tTime: 0:00:00.805328\n",
      "Epoch: [14/50]\tSamples: [235732/841900]\tTrain Loss: 1111.0952605349332\tTime: 0:00:09.729309\n",
      "Epoch: [14/50]\tSamples: [3609/180450]\tValidation Loss: 1100.5001661428028\tTime: 0:00:00.788894\n",
      "Epoch: [15/50]\tSamples: [252570/841900]\tTrain Loss: 1110.7417400490149\tTime: 0:00:09.637958\n",
      "Epoch: [15/50]\tSamples: [3609/180450]\tValidation Loss: 1114.0316071799668\tTime: 0:00:00.796313\n",
      "Epoch: [16/50]\tSamples: [269408/841900]\tTrain Loss: 1110.9013866166742\tTime: 0:00:09.603006\n",
      "Epoch: [16/50]\tSamples: [3609/180450]\tValidation Loss: 1116.194282360505\tTime: 0:00:00.818615\n",
      "Epoch: [17/50]\tSamples: [286246/841900]\tTrain Loss: 1110.7447540649312\tTime: 0:00:09.682603\n",
      "Epoch: [17/50]\tSamples: [3609/180450]\tValidation Loss: 1107.8072527015793\tTime: 0:00:00.803161\n",
      "Epoch: [18/50]\tSamples: [303084/841900]\tTrain Loss: 1109.3414282390406\tTime: 0:00:09.627952\n",
      "Epoch: [18/50]\tSamples: [3609/180450]\tValidation Loss: 1106.994096789277\tTime: 0:00:00.799815\n",
      "Epoch: [19/50]\tSamples: [319922/841900]\tTrain Loss: 1108.6013094277546\tTime: 0:00:09.743918\n",
      "Epoch: [19/50]\tSamples: [3609/180450]\tValidation Loss: 1105.4797414017041\tTime: 0:00:00.794139\n",
      "Early stopping\n",
      "Current call:  9\n",
      "Epoch: [1/50]\tSamples: [16838/841900]\tTrain Loss: 1136.734691550548\tTime: 0:00:07.014395\n",
      "Epoch: [1/50]\tSamples: [3609/180450]\tValidation Loss: 1127.287120739817\tTime: 0:00:00.757231\n",
      "Epoch: [2/50]\tSamples: [33676/841900]\tTrain Loss: 1108.98829796054\tTime: 0:00:06.955983\n",
      "Epoch: [2/50]\tSamples: [3609/180450]\tValidation Loss: 1102.8134213619596\tTime: 0:00:00.737482\n",
      "Epoch: [3/50]\tSamples: [50514/841900]\tTrain Loss: 1104.8617538704075\tTime: 0:00:06.755092\n",
      "Epoch: [3/50]\tSamples: [3609/180450]\tValidation Loss: 1118.454581861319\tTime: 0:00:00.767688\n",
      "Epoch: [4/50]\tSamples: [67352/841900]\tTrain Loss: 1102.68739222608\tTime: 0:00:06.812591\n",
      "Epoch: [4/50]\tSamples: [3609/180450]\tValidation Loss: 1105.1377902899003\tTime: 0:00:00.732405\n",
      "Epoch: [5/50]\tSamples: [84190/841900]\tTrain Loss: 1100.8265704630617\tTime: 0:00:06.817041\n",
      "Epoch: [5/50]\tSamples: [3609/180450]\tValidation Loss: 1092.6275830605778\tTime: 0:00:00.729918\n",
      "Epoch: [6/50]\tSamples: [101028/841900]\tTrain Loss: 1100.024490677244\tTime: 0:00:06.756051\n",
      "Epoch: [6/50]\tSamples: [3609/180450]\tValidation Loss: 1101.121613284497\tTime: 0:00:00.750461\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [7/50]\tSamples: [117866/841900]\tTrain Loss: 1102.586644576952\tTime: 0:00:06.772547\n",
      "Epoch: [7/50]\tSamples: [3609/180450]\tValidation Loss: 1105.1977700064076\tTime: 0:00:00.752322\n",
      "Epoch: [8/50]\tSamples: [134704/841900]\tTrain Loss: 1097.9216123581612\tTime: 0:00:06.872302\n",
      "Epoch: [8/50]\tSamples: [3609/180450]\tValidation Loss: 1102.8263915947978\tTime: 0:00:00.753491\n",
      "Epoch: [9/50]\tSamples: [151542/841900]\tTrain Loss: 1096.021125819737\tTime: 0:00:06.781436\n",
      "Epoch: [9/50]\tSamples: [3609/180450]\tValidation Loss: 1091.0747823908112\tTime: 0:00:00.736370\n",
      "Epoch: [10/50]\tSamples: [168380/841900]\tTrain Loss: 1096.5633678171212\tTime: 0:00:06.771166\n",
      "Epoch: [10/50]\tSamples: [3609/180450]\tValidation Loss: 1094.4108294801192\tTime: 0:00:00.741944\n",
      "Epoch: [11/50]\tSamples: [185218/841900]\tTrain Loss: 1096.92849773856\tTime: 0:00:06.775175\n",
      "Epoch: [11/50]\tSamples: [3609/180450]\tValidation Loss: 1090.5619420415974\tTime: 0:00:00.733392\n",
      "Epoch: [12/50]\tSamples: [202056/841900]\tTrain Loss: 1097.127722824791\tTime: 0:00:06.811973\n",
      "Epoch: [12/50]\tSamples: [3609/180450]\tValidation Loss: 1096.1122941344556\tTime: 0:00:00.748515\n",
      "Epoch: [13/50]\tSamples: [218894/841900]\tTrain Loss: 1097.818311440037\tTime: 0:00:06.853139\n",
      "Epoch: [13/50]\tSamples: [3609/180450]\tValidation Loss: 1092.660598936686\tTime: 0:00:00.733054\n",
      "Epoch: [14/50]\tSamples: [235732/841900]\tTrain Loss: 1094.91366881273\tTime: 0:00:06.762910\n",
      "Epoch: [14/50]\tSamples: [3609/180450]\tValidation Loss: 1091.4637814101898\tTime: 0:00:00.717216\n",
      "Epoch: [15/50]\tSamples: [252570/841900]\tTrain Loss: 1094.7037139577217\tTime: 0:00:06.761342\n",
      "Epoch: [15/50]\tSamples: [3609/180450]\tValidation Loss: 1100.105207900388\tTime: 0:00:00.739281\n",
      "Epoch: [16/50]\tSamples: [269408/841900]\tTrain Loss: 1096.0351192475725\tTime: 0:00:06.774412\n",
      "Epoch: [16/50]\tSamples: [3609/180450]\tValidation Loss: 1098.5506876255542\tTime: 0:00:00.736076\n",
      "Early stopping\n"
     ]
    }
   ],
   "source": [
    "optimization_runs=10\n",
    "model_runs=1\n",
    "optimization_result = optimizer.optimize(\n",
    "    model, dataset, npmi, \n",
    "    search_space, \n",
    "    early_stop=True, \n",
    "    number_of_call=optimization_runs, \n",
    "    model_runs=model_runs, \n",
    "    extra_metrics=[topic_diversity], \n",
    "    save_path=path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "981ca776",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = json.load(open(path+ \"result.json\",\"r\"))\n",
    "max_n = results[ \"f_val\"].index(max(results[ \"f_val\"]))\n",
    "params = [results[\"x_iters\"][parameter][max_n] for parameter in results[\"x_iters\"].keys()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1587cf6f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['activation', 'dropout', 'num_layers', 'num_neurons', 'num_topics'])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results['x_iters'].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "82a22371",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [1/50]\tSamples: [16838/841900]\tTrain Loss: 1134.9879682844248\tTime: 0:00:33.804795\n",
      "Epoch: [1/50]\tSamples: [3609/180450]\tValidation Loss: 1143.9479177490302\tTime: 0:00:01.018436\n",
      "Epoch: [2/50]\tSamples: [33676/841900]\tTrain Loss: 1121.1723154912809\tTime: 0:00:33.623546\n",
      "Epoch: [2/50]\tSamples: [3609/180450]\tValidation Loss: 1139.1670630992235\tTime: 0:00:01.149272\n",
      "Epoch: [3/50]\tSamples: [50514/841900]\tTrain Loss: 1118.2702085452177\tTime: 0:00:34.129766\n",
      "Epoch: [3/50]\tSamples: [3609/180450]\tValidation Loss: 1147.826733858442\tTime: 0:00:01.235061\n",
      "Epoch: [4/50]\tSamples: [67352/841900]\tTrain Loss: 1118.9821073833646\tTime: 0:00:34.094274\n",
      "Epoch: [4/50]\tSamples: [3609/180450]\tValidation Loss: 1133.4556759617342\tTime: 0:00:01.153417\n",
      "Epoch: [5/50]\tSamples: [84190/841900]\tTrain Loss: 1117.9889372601222\tTime: 0:00:35.496224\n",
      "Epoch: [5/50]\tSamples: [3609/180450]\tValidation Loss: 1140.5650474102288\tTime: 0:00:01.165171\n",
      "Epoch: [6/50]\tSamples: [101028/841900]\tTrain Loss: 1118.7085385116975\tTime: 0:00:41.867749\n",
      "Epoch: [6/50]\tSamples: [3609/180450]\tValidation Loss: 1163.2900168740475\tTime: 0:00:01.113947\n",
      "Epoch: [7/50]\tSamples: [117866/841900]\tTrain Loss: 1116.2006642008241\tTime: 0:00:47.294851\n",
      "Epoch: [7/50]\tSamples: [3609/180450]\tValidation Loss: 1140.6097061694181\tTime: 0:00:01.131953\n",
      "Epoch: [8/50]\tSamples: [134704/841900]\tTrain Loss: 1118.3064418384477\tTime: 0:00:48.225670\n",
      "Epoch: [8/50]\tSamples: [3609/180450]\tValidation Loss: 1125.7466491377893\tTime: 0:00:01.143768\n",
      "Epoch: [9/50]\tSamples: [151542/841900]\tTrain Loss: 1116.8029011614121\tTime: 0:00:48.335745\n",
      "Epoch: [9/50]\tSamples: [3609/180450]\tValidation Loss: 1131.956035509371\tTime: 0:00:01.143892\n",
      "Epoch: [10/50]\tSamples: [168380/841900]\tTrain Loss: 1117.1551408406349\tTime: 0:00:48.468457\n",
      "Epoch: [10/50]\tSamples: [3609/180450]\tValidation Loss: 1136.321339730643\tTime: 0:00:01.154933\n",
      "Epoch: [11/50]\tSamples: [185218/841900]\tTrain Loss: 1115.8949160346483\tTime: 0:00:49.127725\n",
      "Epoch: [11/50]\tSamples: [3609/180450]\tValidation Loss: 1156.853174748134\tTime: 0:00:01.135867\n",
      "Epoch: [12/50]\tSamples: [202056/841900]\tTrain Loss: 1118.4873807730166\tTime: 0:00:49.489081\n",
      "Epoch: [12/50]\tSamples: [3609/180450]\tValidation Loss: 1124.988302356089\tTime: 0:00:01.161510\n",
      "Epoch: [13/50]\tSamples: [218894/841900]\tTrain Loss: 1118.4341670411375\tTime: 0:00:48.781763\n",
      "Epoch: [13/50]\tSamples: [3609/180450]\tValidation Loss: 1155.6640404130192\tTime: 0:00:01.146657\n",
      "Epoch: [14/50]\tSamples: [235732/841900]\tTrain Loss: 1114.7262288981767\tTime: 0:00:48.911730\n",
      "Epoch: [14/50]\tSamples: [3609/180450]\tValidation Loss: 1112.178178279345\tTime: 0:00:01.147852\n",
      "Epoch: [15/50]\tSamples: [252570/841900]\tTrain Loss: 1118.0317197655368\tTime: 0:00:48.932134\n",
      "Epoch: [15/50]\tSamples: [3609/180450]\tValidation Loss: 1122.1556456859967\tTime: 0:00:01.120084\n",
      "Epoch: [16/50]\tSamples: [269408/841900]\tTrain Loss: 1116.5409046104676\tTime: 0:00:49.353967\n",
      "Epoch: [16/50]\tSamples: [3609/180450]\tValidation Loss: 1139.762659154793\tTime: 0:00:01.102533\n",
      "Epoch: [17/50]\tSamples: [286246/841900]\tTrain Loss: 1116.205085512436\tTime: 0:00:50.501569\n",
      "Epoch: [17/50]\tSamples: [3609/180450]\tValidation Loss: 1132.4576048012023\tTime: 0:00:01.129589\n",
      "Epoch: [18/50]\tSamples: [303084/841900]\tTrain Loss: 1116.7807309655568\tTime: 0:00:51.186568\n",
      "Epoch: [18/50]\tSamples: [3609/180450]\tValidation Loss: 1137.1286865302022\tTime: 0:00:01.118590\n",
      "Epoch: [19/50]\tSamples: [319922/841900]\tTrain Loss: 1116.6426852971956\tTime: 0:00:53.164995\n",
      "Epoch: [19/50]\tSamples: [3609/180450]\tValidation Loss: 1170.2385054345473\tTime: 0:00:01.127681\n",
      "Early stopping\n"
     ]
    }
   ],
   "source": [
    "model = ProdLDA(solver='adam', num_epochs= 50, num_topics=10,\n",
    "                activation= 'relu', dropout= 0.51, num_layers=2, num_neurons= 150,\n",
    "                batch_size=10)\n",
    "output = model.train_model(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7291db9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#view topics\n",
    "#for topic in output['topics']:\n",
    "#    print(\" \".join(topic))\n",
    "#    print(\"----------------------------------------------------------------------------------------------------------\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
